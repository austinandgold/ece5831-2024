{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('uint8')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x_test[500], cmap=plt.cm.gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Add two layer net in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(100, activation=\"sigmoid\", input_shape=(784, )),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"SGD\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "keras.utils.to_categorical(y_train, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2])\n",
    "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 784)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train/255.0\n",
    "x_test = x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = keras.utils.to_categorical(y_train, num_classes=10)\n",
    "y_test =  keras.utils.to_categorical(y_test, num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 1., 0., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 1.4815 - accuracy: 0.6999\n",
      "Epoch 2/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.7259 - accuracy: 0.8486\n",
      "Epoch 3/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.5352 - accuracy: 0.8722\n",
      "Epoch 4/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.4555 - accuracy: 0.8842\n",
      "Epoch 5/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.4113 - accuracy: 0.8915\n",
      "Epoch 6/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3829 - accuracy: 0.8960\n",
      "Epoch 7/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3627 - accuracy: 0.9005\n",
      "Epoch 8/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.3475 - accuracy: 0.9032\n",
      "Epoch 9/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3352 - accuracy: 0.9062\n",
      "Epoch 10/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3251 - accuracy: 0.9084\n",
      "Epoch 11/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3165 - accuracy: 0.9103\n",
      "Epoch 12/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.3089 - accuracy: 0.9125\n",
      "Epoch 13/20\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.3022 - accuracy: 0.9139\n",
      "Epoch 14/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2961 - accuracy: 0.9153\n",
      "Epoch 15/20\n",
      "1875/1875 [==============================] - 3s 2ms/step - loss: 0.2904 - accuracy: 0.9172\n",
      "Epoch 16/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2852 - accuracy: 0.9185\n",
      "Epoch 17/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2803 - accuracy: 0.9193\n",
      "Epoch 18/20\n",
      "1875/1875 [==============================] - 2s 1ms/step - loss: 0.2757 - accuracy: 0.9211\n",
      "Epoch 19/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2712 - accuracy: 0.9225\n",
      "Epoch 20/20\n",
      "1875/1875 [==============================] - 3s 1ms/step - loss: 0.2669 - accuracy: 0.9233\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2142c29b8e0>"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=20, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(x_test[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.argmax(predictions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 6, 9], dtype=int64)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.argmax(y_test[0:10], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 2, 1, 0, 4, 1, 4, 9, 5, 9], dtype=int64)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "        True])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions == labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#LeNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, AveragePooling2D, Flatten, Dense\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "class LeNet:\n",
    "    def __init__(self, batch_size=32, epochs=20):\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.model = None\n",
    "        self._create_lenet()\n",
    "        self._compile()\n",
    "    \n",
    "\n",
    "    def _create_lenet(self):\n",
    "        self.model = Sequential([\n",
    "            Conv2D(filters=6, kernel_size=(5,5), \n",
    "                   activation='sigmoid', input_shape=(28, 28, 1), \n",
    "                   padding='same'),\n",
    "            AveragePooling2D(pool_size=(2, 2), strides=2),\n",
    "            \n",
    "            Conv2D(filters=16, kernel_size=(5,5), \n",
    "                   activation='sigmoid', \n",
    "                   padding='same'),\n",
    "            AveragePooling2D(pool_size=(2, 2), strides=2),\n",
    "\n",
    "            Flatten(),\n",
    "\n",
    "            Dense(120, activation='sigmoid'),\n",
    "            Dense(84, activation='sigmoid'),\n",
    "            Dense(10, activation='softmax')\n",
    "        ])\n",
    "\n",
    "    def _compile(self):\n",
    "        if self.model is None:\n",
    "            print('Error: Create a model first..')\n",
    "        \n",
    "        self.model.compile(optimizer='Adam',\n",
    "                           loss='categorical_crossentropy',\n",
    "                           metrics=['accuracy'])\n",
    "        \n",
    "\n",
    "    def _preprocess(self):\n",
    "        # load mnist data\n",
    "        (x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "        # normalize\n",
    "        x_train = x_train/255.0\n",
    "        x_test = x_test/255.0\n",
    "\n",
    "        # add channel dim\n",
    "        self.x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)  \n",
    "        self.x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)  \n",
    "\n",
    "        # one-hot encoding\n",
    "        self.y_train = to_categorical(y_train, 10)\n",
    "        self.y_test = to_categorical(y_test, 10)\n",
    "\n",
    "    def train(self):\n",
    "        self._preprocess()\n",
    "        self.model.fit(self.x_train, self.y_train, \n",
    "                  batch_size=self.batch_size, \n",
    "                  epochs=self.epochs)\n",
    "\n",
    "    def save(self, model_path_name):\n",
    "     \n",
    "        try:\n",
    "            # Ensure the directory exists\n",
    "            directory = os.path.dirname(model_path_name)\n",
    "            if directory and not os.path.exists(directory):\n",
    "                os.makedirs(directory)\n",
    "                \n",
    "            # Save the model as a .keras file\n",
    "            self.model.save(model_path_name)\n",
    "            print(f\"Model saved to {model_path_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error saving model: {e}\")\n",
    "    \n",
    "    def load(self, model_path_name):\n",
    "    \n",
    "        try:\n",
    "            # Load the model from the .keras file\n",
    "            self.model = tensorflow.keras.models.load_model(model_path_name)\n",
    "            print(f\"Model loaded from {model_path_name}\")\n",
    "            return self.model\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model: {e}\")\n",
    "            return None\n",
    "\n",
    "    def predict(self, images):\n",
    "            \"\"\"\n",
    "            Predict the class labels for the input images.\n",
    "\n",
    "            Args:\n",
    "                images (list or np.array): A list or array of image data.\n",
    "\n",
    "            Returns:\n",
    "                list: Predicted class probabilities or class labels.\n",
    "            \"\"\"\n",
    "            try:\n",
    "                # If images is a list, convert it to a numpy array\n",
    "                if isinstance(images, list):\n",
    "                    images = np.array(images)\n",
    "                \n",
    "                # Ensure the images are in the correct format (e.g., resized, normalized)\n",
    "                # If images are raw (e.g., not preprocessed), preprocess them\n",
    "                \n",
    "                # Preprocessing images (e.g., resizing to match input shape of model)\n",
    "                processed_images = []\n",
    "                for img in images:\n",
    "                    # If the image is a PIL image or a numpy array, resize it to the expected input size\n",
    "                    # Assuming the model was trained on images of size (32, 32, 3)\n",
    "                    if isinstance(img, np.ndarray):\n",
    "                        img = image.array_to_img(img)  # Convert numpy array to a PIL image if needed\n",
    "                    \n",
    "                    # Resize the image to match model's input size (e.g., 32x32)\n",
    "                    img = img.resize((32, 32))  # Change the size if your model needs a different size\n",
    "                    img = image.img_to_array(img)  # Convert PIL image back to a numpy array\n",
    "                    \n",
    "                    # Normalize the image (if needed, e.g., values between 0 and 1)\n",
    "                    img = img / 255.0  # Assuming the model was trained with normalized images\n",
    "\n",
    "                    # Append to the list of processed images\n",
    "                    processed_images.append(img)\n",
    "\n",
    "                # Convert list of images into a numpy array for prediction\n",
    "                processed_images = np.array(processed_images)\n",
    "\n",
    "                # Make predictions with the model\n",
    "                predictions = self.model.predict(processed_images)\n",
    "                \n",
    "                # If model outputs class probabilities, you can get the predicted class labels:\n",
    "                predicted_labels = np.argmax(predictions, axis=-1)\n",
    "                \n",
    "                return predicted_labels  # or return predictions if you need probabilities\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error making predictions: {e}\")\n",
    "                return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenet = LeNet(batch_size=64, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "938/938 [==============================] - 34s 36ms/step - loss: 1.1475 - accuracy: 0.6136\n",
      "Epoch 2/10\n",
      "938/938 [==============================] - 36s 38ms/step - loss: 0.2424 - accuracy: 0.9273\n",
      "Epoch 3/10\n",
      "938/938 [==============================] - 58s 62ms/step - loss: 0.1571 - accuracy: 0.9523\n",
      "Epoch 4/10\n",
      "938/938 [==============================] - 42s 45ms/step - loss: 0.1146 - accuracy: 0.9654\n",
      "Epoch 5/10\n",
      "938/938 [==============================] - 45s 48ms/step - loss: 0.0918 - accuracy: 0.9716\n",
      "Epoch 6/10\n",
      "938/938 [==============================] - 49s 52ms/step - loss: 0.0774 - accuracy: 0.9761\n",
      "Epoch 7/10\n",
      "938/938 [==============================] - 45s 48ms/step - loss: 0.0667 - accuracy: 0.9790\n",
      "Epoch 8/10\n",
      "938/938 [==============================] - 46s 49ms/step - loss: 0.0591 - accuracy: 0.9810\n",
      "Epoch 9/10\n",
      "938/938 [==============================] - 47s 50ms/step - loss: 0.0523 - accuracy: 0.9835\n",
      "Epoch 10/10\n",
      "938/938 [==============================] - 40s 43ms/step - loss: 0.0471 - accuracy: 0.9854\n"
     ]
    }
   ],
   "source": [
    "lenet.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.reshape(-1,28,28,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x000002142AB89750> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 72ms/step\n"
     ]
    }
   ],
   "source": [
    "predictions = np.argmax(lenet.model.predict(x_test[0:10]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9]\n"
     ]
    }
   ],
   "source": [
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.argmax(lenet.y_test[0:10], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7 2 1 0 4 1 4 9 5 9]\n"
     ]
    }
   ],
   "source": [
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ True  True  True  True  True  True  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "print(predictions == labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_saver = LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to Moore_cnn_model.keras\n"
     ]
    }
   ],
   "source": [
    "model_saver.save('Moore_cnn_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loader = LeNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded from Moore_cnn_model.keras\n"
     ]
    }
   ],
   "source": [
    "model_load = model_loader.load('Moore_cnn_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = 'Custom MNIST Sample/Digit 0/0_0.png'\n",
    "img = Image.open(image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LeNet' object has no attribute 'predict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[127], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m predicted_class \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m([img])\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'LeNet' object has no attribute 'predict'"
     ]
    }
   ],
   "source": [
    "predicted_class = model_loader.predict([img])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece5831-2024",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
